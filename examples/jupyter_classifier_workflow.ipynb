{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce6e2e1-cc12-4d5e-a2c3-b406f2861a8f",
   "metadata": {},
   "source": [
    "# Workflow to train new classifiers in a notebook\n",
    "Classifier training in the napari-feature-classifier Classifier class, using the annotation data from an existing classifier, optionally with different features.\n",
    "Useful when a user annotated data once, then generates new measurements or wants to compare different feature subsets.\n",
    "\n",
    "The current classifier isn't really designed to do this, but it's possible to use it that way\n",
    "\n",
    "Here are the steps taken in this notebook\n",
    "\n",
    "0. Set the parameters\n",
    "1. Load the annotation data that was created by the napari-feature-classifier\n",
    "2. Load the relevant feature measurements\n",
    "3. Create a new classifier instance of the napari-feature-classifier\n",
    "4. Assign the feature data\n",
    "5. Overwrite the training data with the loaded annotation data\n",
    "6. Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba00215e-6f37-4bb9-b7a0-7d9e265bcc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import napari\n",
    "from napari_feature_classifier.classifier import Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522eca55-e7a7-4829-9dea-d598a1e630a7",
   "metadata": {},
   "source": [
    "## 0. Parameters for the user to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81176d41-c1d2-4881-896f-c8483dd4f304",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_path = \"/Users/joel/Desktop/Classifier_data_Conny/Dll1Classifier_log_05022023_train_dataset_48h.csv\"\n",
    "\n",
    "# If base paths need to be changed:\n",
    "old_base_paths = [\"/Users/cornelia/CellClassifier_05022023/\"]\n",
    "new_base_paths = [\"/Users/joel/Desktop/Classifier_data_Conny/FeatureMeasurements/\"]\n",
    "\n",
    "# Column names. The first one is always path. The second one is the column name of the labels\n",
    "index_columns = [\"path\", \"cyto_id_linked\"]\n",
    "\n",
    "training_features = ['Mean_intensity_nuc', 'Median_nuc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527dab21-b0f0-448b-97ef-8945af107127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9107a417-6fdb-4130-80d4-4c8c2508e41e",
   "metadata": {},
   "source": [
    "### 1. Load the annotation data that was created by the napari-feature-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9d59da-7504-4e22-9604-a01752306bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_df = pd.read_csv(annotation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2f051d-1e1a-4041-90ba-f4a61a8c1c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Limit which entries are loaded. e.g. only load the first 148 entries\n",
    "annotation_df = annotation_df[0:147]\n",
    "annotation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09e057f-f92d-45f7-99f4-176fe0b00565",
   "metadata": {},
   "source": [
    "### 2. Load the relevant feature measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b9f3d4-a6dd-48a2-b17c-44117e36963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Only relevant if base paths need to be changed\n",
    "for i in range(len(new_base_paths)):\n",
    "    annotation_df['path'] = annotation_df['path'].str.replace(old_base_paths[i], new_base_paths[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c10053e-2488-4ab6-83e3-51514304018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the feature csv files that need to be loaded\n",
    "features_df = pd.DataFrame()\n",
    "feature_files = annotation_df['path'].unique()\n",
    "for feature_file in feature_files:\n",
    "    sf_df = pd.read_csv(feature_file)\n",
    "    sf_df['path'] = feature_file\n",
    "    features_df = pd.concat([features_df, sf_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dbc2b8-1eda-4e82-9167-b3c4a476b490",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab15f23-95ba-4eae-8489-e7a46792fb1f",
   "metadata": {},
   "source": [
    "### 3. Create a new classifier instance of the napari-feature-classifier & 4. Assign the feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56533943-3985-4e12-9fce-3e26c3025219",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path(\".\")\n",
    "features_clf= features_df.set_index(list(index_columns))\n",
    "clf = Classifier(\n",
    "    name='',\n",
    "    features=features_clf,\n",
    "    training_features=training_features,\n",
    "    directory=save_dir,\n",
    "    method='rfc',\n",
    "    index_columns=index_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52776b03-ab94-4da3-a955-9ccbc039d3c5",
   "metadata": {},
   "source": [
    "### 5. Overwrite the training data with the loaded annotation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9213053a-5920-4c68-ab25-77988a8b7a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match annotation_df with features_df\n",
    "train_tmp = features_clf.merge(annotation_df, how = 'left', on=index_columns).set_index(list(index_columns))\n",
    "clf.train_data.loc[:, 'train'] = train_tmp['train_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abce9ecb-9579-445a-a3ce-2d164f79fda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281685ce-0f74-495f-8b1a-6d9fb96ac848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51e62ea9-5ee1-47b9-9def-3e2f079c5a50",
   "metadata": {},
   "source": [
    "### 6. Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784e91b-4c2e-4cef-9268-e41a63a974fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = clf.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b577926-1e5a-4bae-a2b5-53a3098838a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda1df09-ffbc-41ed-b8db-5c80bfbc04bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Do something with the classifier scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
